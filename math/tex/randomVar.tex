\M
In an election, 50 people vote. We describe all the outcomes in a sample
space $\sampleSpace$, but don't we have a valid question ``How many
voted `yes'?''? 

How can we answer such a question? \emph{Count the number of `yes'-es!}
This is done with a map
\begin{equation}
Y\colon\sampleSpace\to\NN_{0}.
\end{equation}
But what is this mapping? The number of `yes'-es, which depends on the
event. It's a \emph{random variable!}

Note that we can extend the codomain from $\NN_0$ to $\ZZ$, $\QQ$, or
$\RR$. For the sake of generality\footnote{We can sometimes include
$+\infty$, or $-\infty$, if necessary.}, we will consider $\RR$.

\N{Definition}
Let $(\sampleSpace,\mathcal{F},\Pr)$ be a probability space. We define a
\define{Random Variable} to be a function $W\colon\sampleSpace\to\RR$
such that for each $x\in\RR$ we have the set
\begin{equation}
X = \{ \omega\in\sampleSpace : W(\omega)\leq x\}
\end{equation}
be an element of $\mathcal{F}$, or in symbols $X\in\mathcal{F}$. 

\begin{rmk}
We will consider the simpler case of \define{Discrete Random Variables}
$X\colon\sampleSpace\to\ZZ$. 
\end{rmk}

The really critical theoretic property for random variables $X$ is for
any interval $B\subset\RR$, we have a set of outcomes
\begin{equation}
\{\omega\in\sampleSpace : X(\omega)\in B\}
\end{equation}
(denoted $X\in B$) which lives in the $\sigma$-algebra. Studying
$\Pr(X\in B)$ will become increasingly relevant.

\N{Examples}
Lets give a grocery list of examples.
\begin{enumerate}
\item Toss a coin $N$ times, let $H$ be the number of heads.
\item Choose a random point on $\RR^{n}$, let $D$ be the distance from
the point to the origin.
\item Take a random person from a class, let $X$ be the student's
height.
\item Let $W$ be the value of the DOW stock index at closing.
\end{enumerate}

\M
A discrete random variable has countably many values $\{x_{i}\in\RR :
i\in I\subset\ZZ\}$. We take the
convention that its codomain is a subdomain of $\ZZ$. Let $X$ be a
discrete random variable, then its \define{Probability Mass Function}
$p(x_{i}):=\Pr(X=x_{i})$.

\N{Proposition}
A probability mass function $p$ satisfies:
\begin{enumerate}
\item For any $i$, $p(x_{i})>0$
\item For any interval $B$, $\Pr(X\in B)=\sum_{x_{i}\in B}p(x_{i})$
\item We have $\sum_{i}p(x_{i})=1$.
\end{enumerate}

\N{Example}
Let $X$ be the number of heads in 2 fair coin tosses. What is its
probability mass function?

\N*{Solution:} We see there are three outcomes: 0, 1, 2. We also see
that $\Pr(X=0)=1/4$ and $\Pr(X=2)=1/4$. Thus $\Pr(X=1)=1/2$. This gives
us the probability mass function.

\N{Example}
An urn cntains 20 slips of paper numbered 1, \dots, 20. We select 5 at
random, without replacement. Let $X$ be the random variable describing
the greatest value of the 5 slips selected. 

(a) Determine the probability mass function for $X$.

(b) What's the probability at least one of the slips selected is 15 or
greater?

\N*{Solution}
Well, $X$ takes the values 5, \dots, 20. There are $\binom{20}{5}$
different outcomes. So we see
\begin{equation}
\Pr(X\leq k)=\frac{\binom{k}{5}}{\binom{20}{5}}.
\end{equation}
Thus
\begin{equation}
p(k)=\Pr(X\leq k)-\Pr(X\leq k-1)
\end{equation}
and using Pascal's triangle
(theorem \ref{thm:propertiesOfBinomialCoefficients}), we have
\begin{equation}
\begin{split}
p(k) &=\frac{\binom{k}{5}-\binom{k-1}{5}}{\binom{20}{5}}\\
&=\frac{\binom{k-1}{4}}{\binom{20}{5}}
\end{split}
\end{equation}
This gives us the probability mass function.

(b) The probability one of the slips is 15 or greater can be calculated
using
\begin{equation}
\Pr(X\geq15)=\sum^{20}_{k=15}p(k).
\end{equation}
Equivalently, we can calculate it as
\begin{equation}
\begin{split}
\Pr(X\geq15)&=1-\Pr(X\leq14)=\frac{715}{15504}\\
&\approx 0.046117
\end{split}
\end{equation}
or less than a $1/20$ probability.

\N{Definition}
Let $X$ be a discrete random variable taking values $x_{1}$, $x_{2}$, \dots. 
Then the \define{Expected Value} (also called the \emph{average} or 
\emph{mean} or \emph{expectation}) for $X$ is
\begin{equation}
\expected[X] = \sum_{i}x_{i}\Pr(X=x_{i}).
\end{equation}
We also have, for any function $g\colon\RR\to\RR$,
\begin{equation}
\expected[g]=\sum_{i}g(x_{i})\Pr(X=x_{i}).
\end{equation}

\N{Example}
Let $X$ be a random variable such that $\Pr(X=1)=0.2$, $\Pr(X=2)=0.3$ and $\Pr(X=3)=0.5$. What's the expected value of $X$?

\N*{Solution:}
We find, using our definition,
\begin{equation}
\expected[X]=1\Pr(X=1)+2\Pr(X=2)+3\Pr(X=3)
\end{equation}
and this becomes
\begin{equation}
\begin{split}
\expected[X]&=1\cdot0.2+2\cdot0.3+3\cdot0.5\\
&=0.2+0.6+1.5=2.3.
\end{split}
\end{equation}
That concludes our example.

\M
Given some discrete random variable $X$ and its expected value 
$\mu=\expected[X]$, how can we measure the ``spread'' of (the probability 
mass function for) $X$? The na\"{\i}ve solution would use $\expected|X-\mu|$, 
but this is bad since we should avoid absolute values.

So we define the \define{Variance} of $X$ as
\begin{equation}
\Var(X)=\expected(X-\mu)^{2}.
\end{equation}
Notice this intuitively measures the sum of the ``distance squared'' of the 
values $x_i$ from the expected value $\mu$. This has the ``wrong units'' 
(distance squared as opposed to distance). So we just take the square root,
and we obtain the \define{Standard Deviation}
\begin{equation}
\sigma(X)=\sqrt{\Var(X)}=\sqrt{\expected(X-\mu)^{2}}.
\end{equation}

\N{Proposition}
The expected value is linear, i.e., given random variables $X$ and $Y$ and any coefficients $c_1$, $c_2$ we have
\begin{equation}
\expected[c_1 X+c_2Y]=c_1\expected[X]+c_2\expected[Y].
\end{equation}

\M
Also note that
\begin{subequations}
\begin{align}
\Var(X) &= \expected[(X-\mu)^{2}]\\
&= \expected[X^{2}-2\mu X+\mu^{2}]\\
&=\expected[X^{2}]-2\mu\expected[X]+\mu^{2}\\
&=\expected[X^{2}]-2\mu^{2}+\mu^{2}=\expected[X^{2}]-(\expected[X])^{2}.
\end{align}
\end{subequations}
This gives us another intuition for variance!

\M
A \define{Uniform Discrete Random Variable} is a random variable taking values 
$x_1$, $x_2$, \dots, $x_n$ each with equal probability $1/n$. Such a random 
variable simply takes a random choice among $n$ numbers. Note that
\begin{subequations}
\begin{equation}
\expected[X] = \frac{x_{1}+\dots+x_{n}}{n}
\end{equation}
and
\begin{equation}
\Var[X] = \frac{x^{2}_{1}+\dots+x_{n}^{2}}{n}
-\left(\frac{x_{1}+\dots+x_{n}}{n}\right)^{2}.
\end{equation}
\end{subequations}

\N{Example}
Let $X$ be the number shown on a rolled fair die. What's $\expected[X]$ and $\Var(X)$?

\N*{Solution:}
We find
\begin{equation}
\begin{split}
\expected[X] &= \frac{1+2+\dots+6}{6}\\
&=\frac{1}{6}\left(\frac{6(7)}{2}\right)=\frac{7}{2},
\end{split}
\end{equation}
and
\begin{equation}
\expected[X^{2}]=\frac{1+2^{2}+\dots+6^{2}}{6}=\frac{91}{6}
\end{equation}
which then implies
\begin{equation}
\begin{split}
\Var(X)&=\frac{91}{6}-\left(\frac{7}{2}\right)^{2}\\
&=\frac{91}{6}-\frac{49}{4}=\frac{70}{24}=\frac{35}{12}
\end{split}
\end{equation}

\subsection{Bernoull Random Variable}
\M
Let $A$ be an event with probability $p=\Pr(A)$.
We have an \define{Indicator Function} for $A$ be a function defined as
\begin{equation}
I_{A}(x) = \begin{cases}1 & \mbox{if }x\in A\\
0 & \mbox{otherwise}\end{cases}
\end{equation}
Note $I_A$ is a random variable, since it's a function from $\sampleSpace\to\RR$.

\N*{Claim:}
$\expected[I_{A}]=p$. Really? Well, observe
\begin{equation}
\begin{split}
\expected[I_A] &= I_A(A)\Pr(A)+I_A(\comp{A})\Pr(\comp{A})\\
&= 1\cdot p + 0\cdot(1-p) = p.
\end{split}
\end{equation}
What is its variance? We see
\begin{equation}
\expected[I_{A}^{2}]=1^{2}\Pr(A)+0^{2}\Pr(\comp{A})=p,
\end{equation}
thus
\begin{equation}
\Var(I_A)=p-p^{2}=p(1-p).
\end{equation}

\M
Now, recall the ``inclusion-exclusion'' property for probability suggests
\begin{equation}
\Pr(A\cup B)=\Pr(A)+\Pr(B)-\Pr(A\cap B)
\end{equation}
which can be derived using expectation values of Bernoulli random variables. 
Recall
\begin{equation}
I_{A}+I_{\comp{A}}=1
\end{equation}
where we abuse notation and write $1$ for the constant function $I_\sampleSpace$. 
Now, we also see
\begin{equation}
I_{A\cap B}(x)=\begin{cases}1 & \mbox{if }x\in A\mbox{ and }x\in B\\
0 & \mbox{otherwise}
\end{cases}
\end{equation}
thus
\begin{equation}
I_{A\cap B}=I_{A}I_{B}.
\end{equation}
Great.

We now want to consider $I_{A\cup B}$ in terms of $I_{A}$, $I_{B}$, 
and $I_{A\cap B}$. Observe
\begin{equation}
I_{A\cup B} = 1-I_{\comp{(A\cup B)}}=1-I_{\comp{A}\cap\comp{B}}
\end{equation}
replacing $I_{\comp{A}\cap\comp{B}}$ with the product of indicator functions
gives us
\begin{equation}
I_{A\cup B}=1-I_{\comp{A}}I_{\comp{B}}.
\end{equation}
Using the fact $I_{\comp{A}}=1-I_{A}$, we have
\begin{equation}
I_{A\cup B}=1-(1-I_{A})(1-I_{B}).
\end{equation}
Using basic algebra, expanding out the right hand side, we find
\begin{equation}
I_{A\cup B}=I_{A}+I_{B}-I_{A\cap B}.
\end{equation}
Now, we take expectation values to find
\begin{equation}
\begin{split}
\Pr(A\cup B) &=\expected(I_{A\cup B}) 
= \expected[I_A]+\expected[I_B]-\expected[I_{A\cap B}]\\
&=\Pr(A)+\Pr(B)-\Pr(A\cap B).
\end{split}
\end{equation}
This gives us an alternate proof of the inclusion-exclusion principle.

\N{Hat Checker Problem Redux}
We can use indicator functions to solve the hat checker problem, which we 
introduced in subsection \ref{subsec:hatCheckProblem}. Let $\pi$ be a 
permutation of $n$ elements, we want to find the number of fixed points. Let
\begin{equation}
X(\sigma)=\mbox{number of fixed points of $\sigma$}.
\end{equation}
We introduce the indicator function
\begin{equation}
I_{i}(\pi) = \begin{cases}
1 & \mbox{if $i$ is a fixed point of $\pi$}\\
0 & \mbox{otherwise}
\end{cases}
\end{equation}
We now fix a number $r$ such that $0\leq r\leq n-2$. Why $n-2$? We want to
sum over the permutations which do not fix all the points. If we fix $n-1$ points,
then we fix all the points (think about it: if we give $n-1$ people their hats 
correctly, the remaining hat must belong to the remaining person!). 

So we now set
\begin{equation}
\mathcal{S}_{r}=\sum_{\pi\in S_{n}}I_{j_1}(\dots)I_{j_r}(1-I_{k_{r+1}})%
(\dots)(1-I_{k_{n}})
\end{equation}
where we sum over all permutations. Observe there are $n!$ terms in the sum.

If $X(\sigma)\neq r$, we claim $\mathcal{S}_{r}=0$. Why? Well, if 
$X(\sigma)>r$, then one of the $(1-I_{k_{\textstyle{*}}})$ factors vanishes
in every term. If $X(\sigma)<r$, then one of the $I_{j_{\normalsize *}}$ factors
vanishes in every term. 

How many different scenarios do we have $X(\sigma)=r$? There are $r!$
different ways to have fixed points, and $(n-r)!$ different ways to permute
the non-fixed points. Thus
\begin{equation}
\mathcal{S}_{r}=r!(n-r)!
\end{equation}
as desired. So
\begin{equation}
\mathcal{S}_{r}(\sigma) = \begin{cases}r!(n-r)! & \mbox{if $X(\sigma)=r$}\\
0 & \mbox{otherwise}\end{cases}
\end{equation}
Thus we can construct an indicator function
\begin{equation}
\mathcal{I}_{r}=\frac{\mathcal{S}_{r}}{r!(n-r)!}
\end{equation}
which tells us if a permutation has $r$ fixed points.

\N*{Puzzle:}
What's $\expected[\mathcal{I}_{r}]$?

\medbreak
Using linearity, we have
\begin{equation}
\expected[\mathcal{I}_r]=\frac{1}{r!(n-r)!}\expected[\mathcal{S}_{r}],
\end{equation}
and we need to compute $\expected[\mathcal{S}_{r}]$. We find
\begin{equation}
\expected[\mathcal{S}_r] = \expected\left(\sum_{\pi}I_{j_1}(\dots)I_{j_r}(1-I_{k_{r+1}})(\dots)(1-I_{k_n})\right)
\end{equation}
then we expand the $(1-I_{k_{\textstyle *}})$ factors
\begin{multline}
\expected[\mathcal{S}_r] = \expected\Bigg(\sum_{\pi}I_{j_1}(\dots)I_{j_r}
\times\biggl[1-(I_{k_{r+1}}I_{k_{r+2}}+\dots+I_{k_{n-1}}I_{k_n}) \\
+(\dots)+(-1)^{n-r}I_{k_{r+1}}(\dots)I_{k_n}\biggr]\Bigg)
\end{multline}
Now, we claim that
\begin{equation}
\expected[I_{j_1}(\dots)I_{j_{r}}I_{k_{r+s}}]=\expected[I_{j_1}(\dots)I_{j_{r}}I_{k_{r+1}}]
\end{equation}
for $s=1,\dots,n-r$. This means our sum becomes
\begin{equation}
\expected[\mathcal{S}_r]=\sum_{\pi}\sum^{n-r}_{s=0}(-1)^{s}\binom{n-r}{s}
\expected[I_{j_1}(\dots)I_{j_r}I_{k_{r+1}}(\dots)I_{k_{r+s}}]
\end{equation}
where $0\leq s\leq n-r$. So we see
\begin{equation}
\expected[I_{j_1}(\dots)I_{j_r}I_{k_{r+1}}(\dots)I_{k_{r+s}}]=\frac{(n-r-s)!}{n!}
\end{equation}
as there are $n!$ permutations with only $(n-r-s)!$ permutations fixing the 
given entries.

Now, we combine everything together, and find
\begin{subequations}
\begin{align}
\expected[\mathcal{I}_r] &=
\frac{1}{r!(n-r)!}\expected[\mathcal{S}_r]\\
&=\frac{1}{r!(n-r)!}\sum_{\pi}\sum^{n-r}_{s=0}(-1)^{s}\binom{n-r}{s}\frac{(n-r-s)!}{n!}\\
&=\frac{1}{r!(n-r)!}n!\sum^{n-r}_{s=0}(-1)^{s}\binom{n-r}{s}\frac{(n-r-s)!}{n!}\\
&=\frac{1}{r!}\sum^{n-r}_{s=0}\frac{(-1)^{s}}{s!}
\end{align}
\end{subequations}
So, summarizing the main conclusion, the probability that a random permutations 
has exactly $r$ fixed points is given by
\begin{equation}
\Pr(X=r)=\frac{1}{r!}\left(\frac{1}{2!}-\frac{1}{3!}+\dots+\frac{(-1)^{n-r}}{(n-r)!}\right).
\end{equation}
This holds for $0\leq r\leq n-2$. For $r=0$, this converges quickly to the value
\begin{equation}
\frac{1}{E}=0.367 879 441 171\dots
\end{equation}
We have thus derived another solution to the hat check problem using Bernoulli 
random variables.

\subsection{Distribution Functions}
\N{Example/Definition}
Let $X$ be a random variable on $(\sampleSpace,\mathcal{F},\Pr)$. The
\define{Distribution Function} of $X$ is the function
\begin{equation}
F\colon\RR\to[0,1]
\end{equation}
defined by
\begin{equation}
F(x)=\Pr(X\leq x)
\end{equation}
for $x\in\RR$.

Note we use an abbreviation
\begin{equation}
\Pr(X\leq x)=\Pr(\{\omega\in\sampleSpace : X(\omega)\leq x\}).
\end{equation}
This is a subtle point, but an important one!

\N{Example}
Suppose we consider the situation flipping a coin twice, with the random
variable
\begin{equation}
W(HH)=2,\quad\mbox{and}\quad W(HT)=W(TH)=W(TT)=0.
\end{equation}
What is the distribution of $W$?

\N*{Solution:}
We see that
\begin{subequations}
\begin{equation}
\Pr(W\leq 1)=\frac{3}{4}
\end{equation}
and
\begin{equation}
\Pr(W\leq2)=1.
\end{equation}
\end{subequations}
The latter makes intuitive sense since $W(\sampleSpace)=\{0,2\}$. 

\N{Lemma}
A distribution function $F$ for the random variable $X$ has the
following properties: 
\begin{enumerate}
\item $\displaystyle\lim_{x\to-\infty}F(x)=0$
\item $\displaystyle\lim_{x\to+\infty}F(x)=1$
\item If $x<y$, then $F(x)\leq F(y)$
\item We have $F$ be right-continuous, i.e., $F(x+h)\to F(x)$ as
  $h\downarrow 0$.
\end{enumerate}

\begin{proof}
We will prove each proposition.
\begin{enumerate}
\item Consider the sequence of sets $B_{n}=\{\omega\in\sampleSpace :
  X(\omega)\leq-n\}$. We see then that $\dots\subset B_{n+1}\subset
  B_{n}\subset\dots\subset B_{0}$ and obviously $\emptyset$ is the limit
  of this sequence. We have
\begin{equation}
B=\bigcap^{\infty}_{n=0}B_{n}
\end{equation}
satisfy 
\begin{equation}
\Pr(B)=\lim_{n\to\infty}\Pr(B_{n}).
\end{equation}
Then we see $\Pr(B)=\Pr(\emptyset)=0$.
\item The proof is similar, we just have $B_{0}\subset
  B_{1}\subset\dots$ which has its limit be $\sampleSpace$. Thus
  $\Pr(B)=\Pr(\sampleSpace)=1$. 
\item We see that
\begin{subequations}
\begin{equation}
F(x) = \Pr(A)
\end{equation}
where
\begin{equation}
A=\{\omega\in\sampleSpace : X(\omega)\leq x\}
\end{equation}
and similarly
\begin{equation}
F(y)=\Pr(B)
\end{equation}
where
\begin{equation}
A=\{\omega\in\sampleSpace : X(\omega)\leq y\}.
\end{equation}
We see, since $x<y$, that $A\subset B$. Moreover this implies
\begin{equation}
\Pr(A)\leq\Pr(B)
\end{equation}
\end{subequations}
which proves the statement.
\item Consider the sequence of sets
\begin{subequations}
\begin{equation}
B(h) = \{\omega\in\sampleSpace : X(\omega)\leq x+h\}
\end{equation}
We want to prove as $h\downarrow0$ that
$\Pr\bigl(B(h)\bigr)\to\Pr\bigl(B(0)\bigr)$. We see that, if we write 
\begin{equation}
\Delta(h)=B(h)\setminus B(0)
\end{equation}
then we have $B(0)$ and $\Delta(h)$ be disjoint. Thus
\begin{equation}
\Pr\bigl(B(0)\cup\Delta(h)\bigr)-\Pr\bigl(B(0)\bigr)=\Pr\bigl(\Delta(h)\bigr)
\end{equation}
by lemma \ref{lemma:probSpaceProps}. But look, for any sequence
$h_{n}\to0$ as $n\to\infty$, write $\Delta_{n}=\Delta(h_{n})$, then we
have a strictly decreasing sequence
\begin{equation}
\dots\subset\Delta_{n+1}\subset\Delta_{n}\subset\dots\subset\Delta_{0}.
\end{equation}
This has its limit be $\emptyset$, and again this implies
\begin{equation}
\lim_{n\to\infty}\Pr(\Delta_{n})=0
\end{equation}
which proves right-continuity. \qedhere
\end{subequations}
\end{enumerate}
\end{proof}
